{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT ANSWERS BY UTTAM KUMAR SAHOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Mention some advantages of python?\n",
    "Ans:  \n",
    " Following advantages are:\n",
    "\n",
    "* Easy to learn and read:\n",
    "   python's syntax is straighforward and easy to understand making it ideal language for beginners and experienced developers alike.Its readibilty encourages clean and maintainable code, reducing the time required for development and debugging.\n",
    "\n",
    "* Versatile and flexible:\n",
    "    Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming. It can be used for a wide range of applications, such as web development, scientific computing, data analysis, artificial intelligence, automation, scripting, and more.\n",
    "\n",
    "* Large standard library:\n",
    "   Python comes with an extensive standard library that provides ready-to-use modules and functions for various tasks. This vast collection of libraries simplifies development and reduces the need to write code from scratch, saving time and effort.\n",
    "\n",
    "* Community and ecosystem:\n",
    "    Python has a vibrant and active community of developers, which means there are plenty of resources, tutorials, and packages available to help you with your projects. The rich ecosystem includes third-party libraries like NumPy, pandas, TensorFlow,etc.\n",
    "\n",
    "* High productivity:\n",
    "    Due to its simplicity, readability, and extensive libraries, Python enables developers to be more productive. It allows them to focus on solving problems and implementing solutions rather than getting bogged down in complex language features.              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What are local variables and global variables in python?\n",
    "Ans: Local variables are defined within a function or block of code and can only be accessed within that specific function or block.   They have a limited scope and are not accessible outside of it.\n",
    "\n",
    "Global variables, however, are defined outside of any function or block of code and can be accessed from anywhere in the program. They have a broader scope and can be used throughout the entire program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) What is lambda functions in python?\n",
    "Ans:\n",
    " *A lambda function is a small, anonymous function that can have any number of arguments but can only have one expression.\n",
    " *It is defined using the lambda keyword, followed by a list of arguments (if any) separated by commas, a colon (:), and the expression to be evaluated.\n",
    " *The lambda function returns the result of the expression when called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) What is negative index in python?\n",
    "Ans:\n",
    "negative indexing is a feature that allows you to access elements in a sequence (such as a list, tuple, or string) from the end of the sequence instead of the beginning. It provides a convenient way to access elements relative to the end without explicitly calculating the length of the sequence.\n",
    "\n",
    "The index of the last element in a sequence is -1, and the index of the second-to-last element is -2, and so on. The negative indices count backward from the end of the sequence, with -1 representing the last element, -2 representing the second-to-last element, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What is difference between tuples and lists?\n",
    "Ans:\n",
    " *Tuples and lists are two fundamental data structures in Python that are used to store collections of items. They have some similarities, but they also differ in key aspects, such as mutability and syntax.\n",
    "\n",
    " Lists:\n",
    " *Lists are ordered collections of elements that can contain items of different data types (e.g., integers, strings, other lists, etc.).\n",
    " *Lists are defined using square brackets [ ] and elements separated by commas.\n",
    " *Lists are mutable, meaning you can add, remove, or modify elements after the list is created.\n",
    " *Lists support various built-in methods, such as append(), extend(), remove(), pop(), and more, to manipulate the elements.\n",
    " *Lists use zero-based indexing, where the first element has an index of 0, the second has an index of 1, and so on.\n",
    "\n",
    " Tuples:\n",
    " *Tuples are similar to lists in that they are ordered collections of elements and can contain items of different data types.\n",
    " *Tuples are defined using parentheses ( ) and elements separated by commas.\n",
    " *Tuples are immutable, meaning once a tuple is created, you cannot add, remove, or modify its elements.\n",
    " *Tuples support a limited set of methods, primarily for basic operations like counting occurrences of an element or finding the index of an element.\n",
    " *Tuples also use zero-based indexing, just like lists.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What is dynamiclly tyoped language?\n",
    "Ans: \n",
    "  A dynamically typed language is a programming language in which variable types are determined at runtime rather than being explicitly declared by the programmer during variable definition. In dynamically typed languages, the type of a variable is associated with the value it holds, and this type can change as the program runs.\n",
    "\n",
    " Python is an example of a dynamically typed language. When you assign a value to a variable in Python, the interpreter automatically determines the data type of the variable based on the assigned value. You do not need to specify the data type explicitly.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What are the data types available in python?Brief about it?\n",
    "Ans:\n",
    "  Python provides several built-in data types that allow you to work with various types of data. Here's a brief overview of the main data types available in Python:\n",
    "\n",
    "1. Numeric Types:\n",
    "   - `int`: Represents integer numbers, e.g., 1, -3, 100, etc.\n",
    "   - `float`: Represents floating-point numbers with decimal values, e.g., 3.14, -0.5, 2.0, etc.\n",
    "   - `complex`: Represents complex numbers in the form of `a + bj`, where `a` and `b` are real numbers, and `j` is the imaginary unit.\n",
    "\n",
    "2. Text Type:\n",
    "   - `str`: Represents strings, which are sequences of characters enclosed in single quotes (' '), double quotes (\" \"), or triple quotes (''' ''' or \"\"\" \"\"\"). Strings are used to store textual data.\n",
    "\n",
    "3. Sequence Types:\n",
    "   - `list`: Represents ordered collections of elements, enclosed in square brackets `[ ]`. Lists are mutable, meaning you can modify their elements after creation.\n",
    "   - `tuple`: Represents ordered collections of elements, enclosed in parentheses `( )`. Tuples are immutable, and their elements cannot be changed after creation.\n",
    "   - `range`: Represents an immutable sequence of numbers commonly used for looping and generating number ranges.\n",
    "\n",
    "4. Mapping Type:\n",
    "   - `dict`: Represents dictionaries, which store key-value pairs enclosed in curly braces `{ }`. Dictionaries are unordered, mutable, and allow fast access to values based on their keys.\n",
    "\n",
    "5. Set Types:\n",
    "   - `set`: Represents an unordered collection of unique elements, enclosed in curly braces `{ }`. Sets do not allow duplicate values, and they are mutable.\n",
    "   - `frozenset`: Represents an immutable set, meaning its elements cannot be changed after creation.\n",
    "\n",
    "6. Boolean Type:\n",
    "   - `bool`: Represents Boolean values, either `True` or `False`. These are used for logical operations and comparisons.\n",
    "\n",
    "7. None Type:\n",
    "   - `None`: Represents a special type for the `None` object, which denotes the absence of a value or a null value.\n",
    " \n",
    "To determine the data type of a variable or expression, you can use the `type()` function. \n",
    "\n",
    "For example:\n",
    "```python\n",
    "x = 10\n",
    "y = \"Hello\"\n",
    "z = [1, 2, 3]\n",
    "\n",
    "print(type(x))  # Output: <class 'int'>\n",
    "print(type(y))  # Output: <class 'str'>\n",
    "print(type(z))  # Output: <class 'list'>\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Why we have to use functions in python? Explain with an example?\n",
    "Ans:\n",
    "  Functions are an essential concept in programming as they allow you to break down complex tasks into smaller, manageable parts. They offer several advantages, including code reusability, modularity, and readability.functions play a vital role in making Python code organized, efficient, and easier to manage. They are a fundamental building block of programming that enables you to create more structured and maintainable software.\n",
    "\n",
    "\n",
    "  Advantages of functions:\n",
    "  *Code Reusability: Functions allow you to reuse code. In the example above, you can calculate the area of any rectangle, circle, or triangle simply by calling the appropriate function with different input values.\n",
    "\n",
    "  *Modularity: By dividing the code into functions, you can work on each function independently. This modular approach makes the code easier to maintain, update, and debug.\n",
    "\n",
    "  *Readability: Using functions with meaningful names helps in understanding the purpose of each section of code. It enhances code readability and makes it more self-explanatory.\n",
    "\n",
    "  *Abstraction: Functions allow you to abstract away the implementation details and focus on the higher-level logic of your program. This can make your code easier to understand for other developers.\n",
    "\n",
    "  *Encapsulation: Functions can encapsulate a series of instructions, which can be valuable in protecting variables and logic from being accessed or modified unintentionally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What is the difference between function and generations? Give an example?\n",
    "Ans: \n",
    "  Function:\n",
    "  *Functions are blocks of code that are defined using the def keyword and a name, followed by a set of parentheses containing optional parameters, and a colon to define the function body.\n",
    "  *Functions return a value using the return statement.\n",
    "  *When a function is called, it executes the code within its body and returns the result to the caller.\n",
    "  *Functions can be called multiple times, and they start from the beginning every time they are called.\n",
    " \n",
    " Example:\n",
    "  def add_numbers(a, b):\n",
    "    return a + b\n",
    " result = add_numbers(3, 5)\n",
    " print(result)  \n",
    " # Output: 8\n",
    "\n",
    "  Generation:\n",
    " *Generators are functions that use the yield keyword instead of return to produce a sequence of values. When a generator function is called, it doesn't execute the entire function at once but instead returns a generator object.\n",
    " *The generator object allows you to iterate through the sequence of values one at a time using a for loop or the next() function. *Each time you request a new value from the generator, it resumes the function's execution from where it left off.\n",
    " *Generators are memory-efficient because they produce values on-the-fly and do not store the entire sequence in memory.\n",
    "\n",
    "Example:\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        yield n\n",
    "        n -= 1\n",
    "\n",
    "# Creating a generator object\n",
    "counter = countdown(5)\n",
    "\n",
    "# Using the generator to get values one at a time\n",
    "print(next(counter))  # Output: 5\n",
    "print(next(counter))  # Output: 4\n",
    "print(next(counter))  # Output: 3\n",
    "print(next(counter))  # Output: 2\n",
    "print(next(counter))  # Output: 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Explain brief about conditional statements with an example?\n",
    "Ans:\n",
    "\n",
    " *The user is prompted to enter their age using the input() function. The input is converted to an integer using int() and stored in the variable age.\n",
    " *The if statement checks the value of age:\n",
    " *If age is greater than or equal to 18, the code inside the if block is executed, printing \"You are eligible to vote.\"\n",
    " *If age is less than 18, the code inside the else block is executed, printing \"You are not eligible to vote.\"\n",
    " *Depending on the value of age, the appropriate message will be displayed to the user.\n",
    "\n",
    " *In this example, the conditional statement is used to determine whether the user is eligible to vote based on their age. If the condition (age >= 18) is true, the program prints that the user is eligible to vote; otherwise, it prints that they are not eligible.\n",
    "\n",
    " Conditional statements are powerful constructs that allow you to control the flow of your program based on certain conditions. They enable you to make decisions and execute specific blocks of code based on the values of variables or user input, making your programs more interactive and responsive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are eligible to vote.\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "age = int(input(\"Enter your age: \"))\n",
    "\n",
    "# Conditional statement using the 'if' keyword\n",
    "if age >= 18:\n",
    "    print(\"You are eligible to vote.\")\n",
    "else:\n",
    "    print(\"You are not eligible to vote.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Why we have to use exceptional handling in python? What are the keyword used to handle the error , give one example?\n",
    "Ans: \n",
    " Exception handling in Python is essential to gracefully handle runtime errors and unexpected situations that may occur during program execution. When an error or exception occurs in a Python program, it could cause the program to terminate abruptly. Exception handling allows you to catch these errors, handle them in a controlled manner, and take appropriate actions to avoid program crashes and provide meaningful feedback to users.\n",
    "\n",
    "The primary keywords used for exception handling in Python are `try`, `except`, `else`, `finally`, and `raise`.\n",
    "\n",
    "1. `try` and `except`: The `try` block contains the code that might raise an exception. If an exception occurs within the `try` block, the corresponding `except` block is executed, allowing you to handle the exception gracefully.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    num1 = int(input(\"Enter a number: \"))\n",
    "    num2 = int(input(\"Enter another number: \"))\n",
    "    result = num1 / num2\n",
    "    print(\"Result:\", result)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Error: Cannot divide by zero.\")\n",
    "except ValueError:\n",
    "    print(\"Error: Please enter valid integers.\")\n",
    "```\n",
    "\n",
    "2. `else`: The `else` block is optional and is executed if no exceptions occur in the `try` block.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    num1 = int(input(\"Enter a number: \"))\n",
    "    num2 = int(input(\"Enter another number: \"))\n",
    "    result = num1 / num2\n",
    "except ZeroDivisionError:\n",
    "    print(\"Error: Cannot divide by zero.\")\n",
    "except ValueError:\n",
    "    print(\"Error: Please enter valid integers.\")\n",
    "else:\n",
    "    print(\"Result:\", result)\n",
    "```\n",
    "\n",
    "3. `finally`: The `finally` block is optional and is executed regardless of whether an exception occurred or not. It is typically used for cleanup tasks, such as closing files or releasing resources.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    file = open(\"example.txt\", \"r\")\n",
    "    content = file.read()\n",
    "    print(\"File content:\", content)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found.\")\n",
    "finally:\n",
    "    file.close()\n",
    "```\n",
    "\n",
    "\n",
    "4. `raise`: The `raise` keyword is used to raise a specific exception manually.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "def divide(num1, num2):\n",
    "    if num2 == 0:\n",
    "        raise ValueError(\"Cannot divide by zero.\")\n",
    "    return num1 / num2\n",
    "\n",
    "try:\n",
    "    result = divide(10, 0)\n",
    "    print(\"Result:\", result)\n",
    "except ValueError as ve:\n",
    "    print(\"Error:\", ve)\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Define class and object with an example?\n",
    "Ans: \n",
    "In object-oriented programming (OOP), a class is a blueprint or a template that defines the structure and behavior of objects. An object, on the other hand, is an instance of a class. It represents a real-world entity or concept and can interact with other objects and the rest of the program.\n",
    "\n",
    "Example: Creating a class for a simple car and its objects\n",
    "\n",
    "```python\n",
    "# Define a class for a car\n",
    "class Car:\n",
    "    # Constructor method to initialize object attributes\n",
    "    def __init__(self, make, model, year):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.speed = 0\n",
    "\n",
    "    # Method to accelerate the car\n",
    "    def accelerate(self, increment):\n",
    "        self.speed += increment\n",
    "\n",
    "    # Method to brake the car\n",
    "    def brake(self, decrement):\n",
    "        if self.speed >= decrement:\n",
    "            self.speed -= decrement\n",
    "        else:\n",
    "            self.speed = 0\n",
    "\n",
    "# Create objects of the Car class\n",
    "car1 = Car(\"Toyota\", \"Camry\", 2022)\n",
    "car2 = Car(\"Honda\", \"Accord\", 2021)\n",
    "\n",
    "# Accessing object attributes and methods\n",
    "print(f\"{car1.make} {car1.model} ({car1.year})\")\n",
    "print(f\"{car2.make} {car2.model} ({car2.year})\")\n",
    "\n",
    "car1.accelerate(30)\n",
    "print(\"Car 1 Speed:\", car1.speed)  # Output: Car 1 Speed: 30\n",
    "\n",
    "car2.accelerate(20)\n",
    "print(\"Car 2 Speed:\", car2.speed)  # Output: Car 2 Speed: 20\n",
    "\n",
    "car1.brake(10)\n",
    "print(\"Car 1 Speed:\", car1.speed)  # Output: Car 1 Speed: 20\n",
    "\n",
    "car2.brake(5)\n",
    "print(\"Car 2 Speed:\", car2.speed)  # Output: Car 2 Speed: 15\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13) Write a program to swap two numbers?\n",
    "Ans: a = 5\n",
    "b = 10\n",
    "print(\"Before swapping:\")\n",
    "print(\"a =\", a)\n",
    "print(\"b =\", b)\n",
    "a, b = b, a\n",
    "print(\"After swapping:\")\n",
    "print(\"a =\", a)\n",
    "print(\"b =\", b)\n",
    "#output\n",
    "'''Before swapping:\n",
    "   a=5\n",
    "   b=10\n",
    "   After swapping:\n",
    "   a=10\n",
    "   b=5'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the first number: 5\n",
    "Enter the second number: 10\n",
    "After swapping:\n",
    "First number: 10.0\n",
    "Second number: 5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14) Write a palidrome program in python?\n",
    "Ans: def is_palindrome(input_string):\n",
    "    # Remove spaces and convert the string to lowercase\n",
    "    cleaned_string = input_string.replace(\" \", \"\").lower()\n",
    "    \n",
    "    # Compare the cleaned string with its reverse\n",
    "    return cleaned_string == cleaned_string[::-1]\n",
    "\n",
    "# User input\n",
    "user_input = input(\"Enter a string: \")\n",
    "\n",
    "# Check if the input is a palindrome\n",
    "if is_palindrome(user_input):\n",
    "    print(\"It's a palindrome!\")\n",
    "else:\n",
    "    print(\"It's not a palindrome.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a string: level\n",
    "It's a palindrome!\n",
    "\n",
    "Enter a string: Python\n",
    "It's not a palindrome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) What is the use of numpy array over than list?\n",
    "Ans:\n",
    " NumPy arrays offer several advantages over Python lists in certain scenarios due to their specialized data structure and underlying implementation. Here are some of the key reasons why you might choose to use NumPy arrays over lists:\n",
    "\n",
    "1. Performance:\n",
    "   - NumPy arrays are implemented in C and provide better performance for numerical computations, especially when dealing with large datasets. This is because NumPy arrays use contiguous memory, allowing for faster element-wise operations.\n",
    "   - In contrast, Python lists are dynamic arrays with overhead due to their variable size and additional type checking, making them slower for numerical computations.\n",
    "\n",
    "2. Memory Efficiency:\n",
    "   - NumPy arrays are more memory-efficient compared to lists, especially when working with large datasets. NumPy uses fixed-size data types, which reduce memory overhead compared to the dynamically-typed objects of Python lists.\n",
    "\n",
    "3. Broadcasting and Vectorized Operations:\n",
    "   - NumPy supports broadcasting, which allows operations between arrays of different shapes and dimensions. This feature simplifies vectorized operations, making element-wise calculations more concise and readable.\n",
    "   - While you can perform element-wise operations with Python lists, it usually requires writing explicit loops, leading to less efficient code.\n",
    "\n",
    "4. Mathematical and Statistical Functions:\n",
    "   - NumPy provides an extensive library of mathematical and statistical functions, making it a powerful tool for data analysis, numerical simulations, and scientific computing.\n",
    "   - Python lists lack these specialized mathematical functionalities, and you would need to implement custom functions or rely on external libraries.\n",
    "\n",
    "5. Multidimensional Arrays:\n",
    "   - NumPy arrays can have multiple dimensions, which is crucial for representing matrices, images, and other complex data structures.\n",
    "   - Python lists can represent nested lists, but handling multidimensional data with lists can be cumbersome and less efficient.\n",
    "\n",
    "6. Interoperability with Other Libraries:\n",
    "   - NumPy is a fundamental building block for many scientific and data-related libraries in Python, such as Pandas, SciPy, and scikit-learn. Using NumPy arrays ensures compatibility and seamless integration with these libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Explain brief about reshape in numpy with an example?\n",
    "Ans: \n",
    "In NumPy, the `reshape()` function is used to change the shape of an array without modifying its data. It allows you to create a new view of the data with a different shape, enabling you to reorganize the elements of the array into a new structure.\n",
    "\n",
    "Here's a brief explanation of `reshape()` with an example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Creating a 1D NumPy array\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Using reshape() to convert the 1D array to a 2D array\n",
    "reshaped_arr = arr.reshape((2, 3))\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "\n",
    "print(\"Reshaped array:\")\n",
    "print(reshaped_arr)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Original array:\n",
    "[1 2 3 4 5 6]\n",
    "\n",
    "Reshaped array:\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) What is the use of pandas explain in brief?\n",
    "Ans:- Pandas is a popular Python library used for data manipulation and analysis. In short and simple words, Pandas is used for:\n",
    "     -Reading and writing data: It allows you to read data from various file formats like CSV, Excel, and SQL databases, and write data back to       these formats.\n",
    "     -Data cleaning and preprocessing: It provides powerful tools for handling missing data, removing duplicates, and transforming data into a         suitable format for analysis.\n",
    "     -Data manipulation: Pandas allows you to filter, sort, group, and aggregate data, enabling you to extract meaningful insights and summaries       from large datasets.\n",
    "     -Data analysis and visualization: It supports various statistical operations and integrates well with other libraries like Matplotlib and         Seaborn for data visualization.\n",
    "     -Time series data handling: Pandas has excellent support for working with time series data, making it valuable in finance, economics, and         other time-dependent domains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) What do you mean by supervised machine learning and unsupervised machine learning?Explain in brief?\n",
    "Ans:\n",
    "Supervised Machine Learning:\n",
    "\n",
    "In supervised machine learning, the algorithm learns from a labeled dataset, where each input data point is associated with a corresponding output label or target value. The goal of supervised learning is to build a predictive model that can map inputs to their respective outputs accurately. During training, the algorithm iteratively adjusts its parameters based on the known inputs and outputs to make accurate predictions on unseen data.\n",
    "\n",
    "Example:\n",
    " Given a dataset of images of cats and dogs, along with their corresponding labels (\"cat\" or \"dog\"), a supervised learning algorithm will learn to recognize and distinguish between cats and dogs in new images.\n",
    "\n",
    "Unsupervised Machine Learning:\n",
    "\n",
    "In unsupervised machine learning, the algorithm learns from an unlabeled dataset, where the input data points have no corresponding output labels. The objective of unsupervised learning is to identify patterns, structures, or relationships within the data without explicit guidance. The algorithm tries to find natural groupings or clusters in the data based on inherent similarities or differences.\n",
    "\n",
    "Example:\n",
    " Given a dataset of customer purchase history without any labels, an unsupervised learning algorithm can identify distinct groups of customers based on their purchasing behavior, which can help in targeted marketing or customer segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Difference between decision tree and random forest?\n",
    "Ans: \n",
    "A decision tree is a flowchart-like structure with internal nodes representing features, branches representing decision rules, and leaf          nodes representing outcomes or class labels. It recursively splits data based on features until a stopping criterion is met. Decision trees      are easy to interpret but can overfit.\n",
    "     Random forest is an ensemble method that combines multiple decision trees. It creates a set of trees on randomly selected data subsets and      aggregates predictions through voting or averaging. Random forest reduces overfitting, improves accuracy, and enhances model robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) What do you mean by forward propogation and backward propogation in ANN?\n",
    "Ans:\n",
    " In Artificial Neural Networks (ANN), forward propagation and backward propagation are fundamental steps involved in the training process. These steps are used to compute predictions and update the network's parameters (weights and biases) to minimize the prediction error during the training process.\n",
    "\n",
    "1. **Forward Propagation:**\n",
    "   Forward propagation is the process of computing the output of the neural network given an input. It involves passing the input data through the network layer by layer, from the input layer to the output layer, while performing computations in each neuron.\n",
    "\n",
    "   Here's a high-level overview of the forward propagation process:\n",
    "   - The input data is fed into the input layer of the neural network.\n",
    "   - Each neuron in a layer processes the input it receives by applying an activation function to the weighted sum of its inputs (input data or outputs from previous layers).\n",
    "   - The output of each neuron in a layer becomes the input for the neurons in the next layer.\n",
    "   - This process continues through all the layers until the output layer produces the final predictions or outputs of the network.\n",
    "\n",
    "   Mathematically, the forward propagation process can be represented as follows:\n",
    "\n",
    "   ```\n",
    "   z[1] = W[1] * X + b[1]\n",
    "   a[1] = activation(z[1])\n",
    "\n",
    "   z[2] = W[2] * a[1] + b[2]\n",
    "   a[2] = activation(z[2])\n",
    "\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "2. **Backward Propagation (Backpropagation):**\n",
    "   Backward propagation is the process of updating the neural network's parameters (weights and biases) based on the error or loss computed during forward propagation. It aims to minimize the difference between the predicted outputs and the actual targets.\n",
    "\n",
    "   Here's a high-level overview of the backward propagation process:\n",
    "   - The loss function (a measure of the prediction error) is calculated by comparing the predicted outputs with the true labels (target values).\n",
    "   - The derivative of the loss function with respect to the parameters (weights and biases) is computed, indicating how the loss changes concerning each parameter.\n",
    "   - The gradients are propagated backward from the output layer to the input layer.\n",
    "   - The weights and biases are updated in the opposite direction of the gradients, using optimization algorithms like Gradient Descent, Stochastic Gradient Descent, or Adam.\n",
    "\n",
    "   Mathematically, the backward propagation process involves calculating the gradients of the loss function with respect to the parameters and updating the parameters to minimize the loss.\n",
    "\n",
    "ANNs use the combination of forward propagation and backward propagation iteratively during the training process to learn from data and adjust the network's parameters to improve prediction accuracy. This training process is often referred to as the \"learning\" phase of the neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) Explain the workig flow of ANN and CNN?\n",
    "Ans: \n",
    "\n",
    "Working Flow of Artificial Neural Networks (ANN):\n",
    "\n",
    "1. Input Layer: The input layer receives the raw input data, such as images, tabular data, or any other structured data. Each input node in the input layer represents a feature or attribute of the data.\n",
    "\n",
    "2. Weighted Sum and Activation: Each neuron in the hidden layers and output layer calculates a weighted sum of its inputs from the previous layer. It multiplies the input values with corresponding weights and adds a bias term. The weighted sum is then passed through an activation function, which introduces non-linearity into the model. Common activation functions include Sigmoid, ReLU (Rectified Linear Unit), and Tanh.\n",
    "\n",
    "3. Forward Propagation: The input data is fed into the neural network, and the calculations (weighted sum and activation) are performed layer by layer, propagating forward through the network until the final output is obtained.\n",
    "\n",
    "4. Loss Function: The output layer produces the predicted values. These predictions are compared to the actual target values using a loss function (also called a cost function), which measures the difference between the predicted and true values.\n",
    "\n",
    "5. Backward Propagation (Backpropagation):After the forward propagation, the neural network computes the loss and then iteratively adjusts its parameters (weights and biases) using an optimization algorithm. This process is known as backward propagation or backpropagation. The gradients of the loss function with respect to the parameters are calculated, and the parameters are updated to minimize the loss.\n",
    "\n",
    "6. Training: The forward and backward propagation steps are repeated over multiple epochs (iterations) during the training phase. The network learns from the data and updates its parameters to minimize the prediction error.\n",
    "\n",
    "7. Prediction: Once the ANN is trained, it can make predictions on new, unseen data by performing a forward pass through the network.\n",
    "\n",
    "Working Flow of Convolutional Neural Networks (CNN):\n",
    "1. Input Layer: Similar to ANN, the input layer of a CNN receives the raw input data, typically images or other grid-like data. Each input node represents a pixel or a small patch of the image.\n",
    "\n",
    "2. Convolutional Layer: The core operation in a CNN is the convolution operation. The convolutional layer consists of multiple learnable filters (also called kernels), each having a small receptive field. The filters are applied across the input data (e.g., image) to detect different features or patterns.\n",
    "\n",
    "3. Activation and Pooling: After the convolution operation, an activation function (commonly ReLU) is applied to introduce non-linearity. Subsequently, a pooling layer (such as MaxPooling) is used to reduce the spatial dimensions of the feature maps, reducing computational complexity and making the network more robust to translations.\n",
    "\n",
    "4. Fully Connected Layers: After several convolutional and pooling layers, the data is flattened and passed through fully connected layers, similar to ANN, to learn higher-level representations and make predictions.\n",
    "\n",
    "5. Loss Function and Backpropagation: Like ANN, CNN uses a loss function to measure the difference between predicted and true values. Backpropagation is then applied to update the parameters (weights and biases) of the filters and fully connected layers to minimize the loss.\n",
    "\n",
    "6. Training and Prediction: The CNN is trained through forward and backward propagation over multiple epochs, learning the relevant features for the specific task. Once trained, the CNN can make predictions on new images or data by performing a forward pass through the network.\n",
    "\n",
    "CNNs are especially powerful for tasks involving image recognition, object detection, and other computer vision tasks due to their ability to learn local patterns and hierarchical features from raw pixel data. They have become a cornerstone of modern computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) What is the use of activation function and optimizers?\n",
    "Ans: \n",
    "\n",
    "Activation Function:\n",
    "\n",
    "Activation functions play a crucial role in Artificial Neural Networks (ANNs) by introducing non-linearity into the model. Without non-linear activation functions, the whole network would behave like a linear model, making it limited in its ability to learn complex patterns and relationships in the data. The activation function is applied to the weighted sum of the inputs in each neuron, transforming the output and introducing non-linearities.\n",
    "\n",
    "Main Uses of Activation Functions:\n",
    "1. Non-Linearity: Activation functions introduce non-linearity, enabling ANNs to approximate complex and non-linear functions in the data, making them capable of learning intricate patterns.\n",
    "\n",
    "2. Gradient Descent: During backpropagation, the gradients are computed based on the derivatives of the activation function. The non-linear activation functions allow the network to update its weights and biases effectively.\n",
    "\n",
    "3. Feature Extraction: Different activation functions respond differently to the inputs, allowing them to extract different features from the data. Choosing appropriate activation functions can help the network learn and emphasize relevant features.\n",
    "\n",
    "Common Activation Functions:\n",
    "- Sigmoid: Transforms the input to a range between 0 and 1, suitable for binary classification problems.\n",
    "- ReLU (Rectified Linear Unit): Sets all negative inputs to zero and keeps positive inputs unchanged, widely used in hidden layers for better training convergence.\n",
    "- Tanh (Hyperbolic Tangent): Similar to the sigmoid function, but outputs values in the range between -1 and 1, useful for hidden layers.\n",
    "\n",
    "\n",
    "Optimizers:\n",
    "\n",
    "Optimizers are algorithms used in the training phase of machine learning models, including ANNs, to minimize the loss function and update the model's parameters (weights and biases). During training, the objective is to find the optimal set of parameters that best fit the data.\n",
    "\n",
    "Main Uses of Optimizers:\n",
    "1. Gradient-Based Optimization: Optimizers leverage the gradients computed during backpropagation to determine the direction and magnitude of parameter updates, leading to faster convergence during training.\n",
    "\n",
    "2. Minimization of Loss Function: Optimizers aim to minimize the loss function by adjusting the model's parameters iteratively, thus improving the model's performance on the training data.\n",
    "\n",
    "3. Learning Rate Control: Many optimizers use learning rate as a hyperparameter to control the step size of parameter updates. Adaptive optimizers automatically adjust the learning rate based on the gradient magnitude or past update history.\n",
    "\n",
    "Common Optimizers:\n",
    "- Gradient Descent: A basic optimization algorithm that updates parameters in the direction of the steepest descent of the loss function.\n",
    "- Stochastic Gradient Descent (SGD): A variant of gradient descent that updates parameters based on a random subset (mini-batch) of the training data, which improves convergence speed.\n",
    "- Adam (Adaptive Moment Estimation): An adaptive optimization algorithm that adjusts the learning rate based on the moving average of past squared gradients, effectively combining the advantages of RMSprop and momentum methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) What is the difference between R square and adjusted R square?\n",
    "Ans:\n",
    "R-squared (R²) and adjusted R-squared (adjusted R²) are both metrics used to evaluate the goodness of fit of a regression model. They provide insights into how well the model explains the variance in the dependent variable. However, there is a fundamental difference between the two:\n",
    "\n",
    "**R-squared (R²):**\n",
    "- R-squared is a statistical measure that represents the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features) in the regression model.\n",
    "- It ranges between 0 and 1, with higher values indicating a better fit of the model to the data.\n",
    "- R-squared measures the overall fit of the model and represents the percentage of the total variation in the dependent variable that is explained by the independent variables.\n",
    "\n",
    "**Adjusted R-squared (adjusted R²):**\n",
    "- Adjusted R-squared is an extension of R-squared that takes into account the number of independent variables used in the model and penalizes the addition of irrelevant variables.\n",
    "- It adjusts R-squared to account for the fact that adding more variables to the model may artificially increase R-squared, even if the added variables do not significantly improve the model's predictive power.\n",
    "- Adjusted R-squared penalizes the model for the inclusion of less relevant features, thereby providing a more realistic and unbiased estimate of the model's goodness of fit.\n",
    "- Like R-squared, adjusted R-squared also ranges between 0 and 1, and higher values indicate a better fit of the model.\n",
    "\n",
    "The formula for adjusted R-squared is:\n",
    "\n",
    "```\n",
    "Adjusted R² = 1 - [(1 - R²) * (n - 1) / (n - p - 1)]\n",
    "```\n",
    "\n",
    "where:\n",
    "- R² is the regular R-squared value.\n",
    "- n is the number of observations (data points).\n",
    "- p is the number of independent variables (features) in the model.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) What do you mean by LSTM in RNN?\n",
    "Ans :\n",
    "LSTM stands for Long Short-Term Memory, and it is a type of recurrent neural network (RNN) architecture. RNNs are designed to process sequential data, where the order and context of the data are essential, such as time series data, natural language, speech, and more.\n",
    "\n",
    "The standard RNNs suffer from the vanishing gradient problem, which makes it challenging to capture long-term dependencies in sequences. LSTM was introduced to address this issue by using a more sophisticated memory mechanism that allows the model to retain information for longer periods.\n",
    "\n",
    "Key Characteristics of LSTM:\n",
    "1. **Memory Cell:** The core component of an LSTM is the memory cell. The memory cell stores information over time and can selectively add or remove information from the cell state.\n",
    "\n",
    "2. **Three Gates:** LSTM introduces three gates to control the flow of information in and out of the memory cell:\n",
    "   - Forget Gate: Determines what information to discard from the previous state.\n",
    "   - Input Gate: Decides what new information to store in the cell state.\n",
    "   - Output Gate: Determines what information to output from the cell state.\n",
    "\n",
    "3. **Long-Term Memory:** The LSTM's design enables it to learn and retain information for long periods, making it effective in capturing long-range dependencies in sequential data.\n",
    "\n",
    "4. **Backpropagation Through Time (BPTT):** Like other RNNs, LSTM uses backpropagation through time to train the model. During training, the model learns the appropriate weights and biases for the memory cell and the gates.\n",
    "\n",
    "LSTM Architecture:\n",
    "\n",
    "The architecture of an LSTM cell is more complex than a standard RNN cell due to the presence of the memory cell and the three gates. At each time step, the LSTM cell takes an input, the previous hidden state, and the previous cell state as inputs and produces the current hidden state and the current cell state as outputs.\n",
    "\n",
    "The equations governing the LSTM cell operations can be summarized as follows (assuming a single LSTM cell):\n",
    "\n",
    "```\n",
    "Input at time t: x(t)\n",
    "Previous hidden state: h(t-1)\n",
    "Previous cell state: c(t-1)\n",
    "\n",
    "Forget Gate: f(t) = sigmoid(W_f * [h(t-1), x(t)] + b_f)\n",
    "Input Gate: i(t) = sigmoid(W_i * [h(t-1), x(t)] + b_i)\n",
    "Candidate Cell State: ĉ(t) = tanh(W_c * [h(t-1), x(t)] + b_c)\n",
    "Current Cell State: c(t) = f(t) * c(t-1) + i(t) * ĉ(t)\n",
    "Output Gate: o(t) = sigmoid(W_o * [h(t-1), x(t)] + b_o)\n",
    "Current Hidden State: h(t) = o(t) * tanh(c(t))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25) What is the use of image processing?\n",
    "Ans:\n",
    "Image processing is a field of computer science and engineering that deals with the analysis, manipulation, and enhancement of digital images. It plays a vital role in various applications and industries due to its ability to extract valuable information from images, improve visual quality, and facilitate decision-making processes. Here are some common uses of image processing:\n",
    "\n",
    "1. **Medical Imaging:** In the field of medicine, image processing is extensively used for tasks like image enhancement, segmentation, and registration. It aids in the diagnosis of diseases, locating tumors, and monitoring the progress of treatments through techniques such as MRI, CT scans, X-rays, and ultrasound images.\n",
    "\n",
    "2. **Computer Vision:** Image processing is a core component of computer vision systems that enable machines to interpret and understand visual information from images and videos. Applications include object detection, face recognition, gesture recognition, autonomous vehicles, and robotics.\n",
    "\n",
    "3. **Remote Sensing:** Image processing is used in analyzing satellite and aerial images for applications such as land-use mapping, environmental monitoring, disaster management, agriculture, and urban planning.\n",
    "\n",
    "4. **Digital Photography:** Image processing is widely used in digital cameras and smartphone cameras to improve image quality, remove noise, correct colors, and apply various artistic filters.\n",
    "\n",
    "5. **Entertainment and Gaming:** Image processing techniques are used in the entertainment industry to create visual effects in movies, video games, and augmented reality applications.\n",
    "\n",
    "6. **Security and Surveillance:** Image processing is employed in security systems for tasks like object tracking, face recognition, and anomaly detection, enhancing the effectiveness of surveillance cameras.\n",
    "\n",
    "7. **Biometrics:** Image processing is used in biometric systems for tasks like fingerprint recognition, iris recognition, and vein pattern recognition, contributing to secure authentication and identification.\n",
    "\n",
    "8. **Character Recognition:** Image processing is applied in Optical Character Recognition (OCR) systems to extract text from scanned documents, making it useful in data entry and document digitization.\n",
    "\n",
    "9. **Artificial Intelligence and Deep Learning:** Image processing is a fundamental part of pre-processing image data in machine learning and deep learning models for various image-related tasks.\n",
    "\n",
    "10. **Forensics and Image Analysis:** Image processing is utilized in forensic investigations for tasks like fingerprint analysis, facial composite generation, and image enhancement to aid in solving criminal cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26) What are the steps involved in NPL?\n",
    "Ans:\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language. The process of NLP involves several steps to process and analyze natural language data. Here are the key steps involved in NLP:\n",
    "\n",
    "1. **Tokenization:**\n",
    "   - Tokenization is the process of breaking down a text or sentence into individual words or tokens.\n",
    "   - It involves removing punctuation, splitting text into words, and handling contractions and hyphenated words.\n",
    "\n",
    "2. **Text Preprocessing:**\n",
    "   - Text preprocessing includes tasks like converting text to lowercase, removing stop words (common words like \"the,\" \"is,\" \"and\"), and handling special characters and numbers.\n",
    "   - Lemmatization or stemming might be performed to reduce words to their base or root form.\n",
    "\n",
    "3. **Part-of-Speech Tagging:**\n",
    "   - Part-of-speech tagging involves labeling each word in a sentence with its corresponding part of speech (e.g., noun, verb, adjective).\n",
    "   - It helps in understanding the grammatical structure of the text and disambiguating word meanings.\n",
    "\n",
    "4. **Named Entity Recognition (NER):**\n",
    "   - NER is the process of identifying and classifying named entities in the text, such as person names, locations, organizations, dates, and other named objects.\n",
    "   - NER is crucial for extracting structured information from unstructured text.\n",
    "\n",
    "5. **Syntax and Dependency Parsing:**\n",
    "   - Syntax parsing involves analyzing the sentence structure and identifying the grammatical relationships between words.\n",
    "   - Dependency parsing aims to identify the dependencies between words in a sentence.\n",
    "\n",
    "6. **Sentiment Analysis:**\n",
    "   - Sentiment analysis determines the sentiment expressed in a piece of text, whether it is positive, negative, or neutral.\n",
    "   - It is often used for social media monitoring, customer feedback analysis, and brand reputation management.\n",
    "\n",
    "7. **Topic Modeling:**\n",
    "   - Topic modeling is the process of identifying topics or themes within a collection of text documents.\n",
    "   - Techniques like Latent Dirichlet Allocation (LDA) are commonly used for topic modeling.\n",
    "\n",
    "8. **Machine Translation:**\n",
    "   - Machine translation involves translating text from one language to another.\n",
    "   - Statistical and neural machine translation methods are commonly used for this task.\n",
    "\n",
    "9. **Text Generation:**\n",
    "   - Text generation involves using language models to generate human-like text, such as chatbot responses, language translation, and creative writing.\n",
    "\n",
    "10. **Text Classification and Clustering:**\n",
    "   - Text classification assigns predefined categories or labels to text documents based on their content.\n",
    "   - Text clustering groups similar documents together without predefined categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27) What do you mean by bias and varience?\n",
    "Ans:\n",
    "Bias and variance are two important concepts in the context of supervised machine learning models, particularly in the context of regression and classification problems. They represent two different sources of error in a model's predictions.\n",
    "\n",
    "1. **Bias:**\n",
    "   - Bias refers to the error introduced by approximating a real-world problem with a simplified model. It represents the model's tendency to consistently underfit or overfit the training data.\n",
    "   - In simpler terms, bias measures how far off the predictions are from the true values or the actual data points.\n",
    "   - A model with high bias is likely to be too simplistic and unable to capture the underlying patterns in the data. Such models may perform poorly on both the training data and unseen test data, leading to low accuracy and poor generalization.\n",
    "   - High bias can result from using a model that is too simple or when important features in the data are ignored or not considered.\n",
    "\n",
    "2. **Variance:**\n",
    "   - Variance refers to the error introduced due to the model's sensitivity to fluctuations in the training data.\n",
    "   - It measures the variability of the model's predictions when trained on different subsets of the training data.\n",
    "   - A model with high variance is likely to overfit the training data, meaning it memorizes noise or random fluctuations in the data instead of learning the underlying patterns. As a result, the model may perform very well on the training data but poorly on new, unseen data (i.e., it lacks generalization ability).\n",
    "   - High variance can arise when using complex models that have many degrees of freedom, such as deep neural networks or high-degree polynomial regression models.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28)What are the steps to create a model in machine learning?\n",
    "Ans:\n",
    "Creating a machine learning model involves several important steps. Here is a general outline of the steps involved in building and training a machine learning model:\n",
    "\n",
    "1. **Define the Problem:**\n",
    "   - Clearly define the problem you want to solve with machine learning. Decide whether it's a regression, classification, or other type of problem.\n",
    "\n",
    "2. **Gather and Preprocess Data:**\n",
    "   - Collect relevant data for your problem. The data should be in a format suitable for machine learning.\n",
    "   - Preprocess the data by handling missing values, removing noise, and scaling or normalizing the features.\n",
    "\n",
    "3. **Split Data into Training and Testing Sets:**\n",
    "   - Divide the data into two sets: the training set (used for model training) and the testing set (used for model evaluation).\n",
    "   - This step is crucial to ensure that the model's performance on unseen data can be accurately assessed.\n",
    "\n",
    "4. **Choose a Model:**\n",
    "   - Select an appropriate machine learning algorithm or model that is suitable for your problem.\n",
    "   - The choice of the model depends on the nature of the problem (e.g., linear regression for regression, logistic regression for binary classification, decision trees, support vector machines, neural networks, etc.).\n",
    "\n",
    "5. **Train the Model:**\n",
    "   - Feed the training data into the model and let it learn from the patterns in the data.\n",
    "   - During training, the model adjusts its parameters (weights and biases) to minimize the error or loss function.\n",
    "\n",
    "6. **Evaluate the Model:**\n",
    "   - Use the testing set to evaluate the model's performance on unseen data.\n",
    "   - Common evaluation metrics depend on the problem type (e.g., mean squared error for regression, accuracy, precision, recall, F1-score for classification).\n",
    "\n",
    "7. **Hyperparameter Tuning:**\n",
    "   - Fine-tune the model's hyperparameters to improve its performance.\n",
    "   - Hyperparameters are settings that are not learned during training, such as learning rate, regularization strength, number of layers, etc.\n",
    "\n",
    "8. **Finalize the Model:**\n",
    "   - Once you are satisfied with the model's performance, train it on the entire dataset (training and testing sets combined) to maximize its learning potential.\n",
    "   - This step ensures that the model can generalize well to new, unseen data.\n",
    "\n",
    "9. **Deploy the Model:**\n",
    "   - Integrate the trained model into your application or system for real-world use.\n",
    "   - The model is now ready to make predictions on new data.\n",
    "\n",
    "10. **Monitor and Maintain the Model:**\n",
    "   - Continuously monitor the model's performance in the real-world setting.\n",
    "   - Retrain the model periodically if the data distribution changes or new data becomes available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
